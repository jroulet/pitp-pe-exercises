{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f79013a-2f28-4781-b4dc-e9e6b569fd94",
   "metadata": {},
   "source": [
    "# Parameter estimation with `cogwheel`\n",
    "\n",
    "In this exercise we will learn to:\n",
    "\n",
    "* Estimate the chirp mass of a signal from its frequency evolution\n",
    "* Use the software `cogwheel` to:\n",
    "    - Generate a synthetic event (\"injection\") in Gaussian noise\n",
    "    - Plot whitened data as a spectrogram or time series\n",
    "    - Find a good-fit waveform\n",
    "    - Sample the posterior distribution using nested sampling\n",
    "    - Corner-plot the posterior distribution\n",
    "\n",
    "For reference, here are `cogwheel`'s [documentation](https://cogwheel.readthedocs.io/en/latest/index.html) and [source code (GitHub)](https://github.com/jroulet/cogwheel). You can find additional tutorials in the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b898e1-91c6-4e04-b5f8-c91ac565ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cogwheel.cosmology\n",
    "import cogwheel.data\n",
    "import cogwheel.posterior\n",
    "import cogwheel.sampling\n",
    "import cogwheel.gw_plotting\n",
    "import cogwheel.gw_utils\n",
    "\n",
    "import lal\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "# Only needed on Apple M4 with numpy<2.3 https://github.com/numpy/numpy/issues/28687\n",
    "# (still, ok on other systems)\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58ac5dd-3e09-44f4-b168-129fcd5c2271",
   "metadata": {},
   "source": [
    "## Simulate a new detected event\n",
    "\n",
    "To simulate a detection where we don't know the parameters in advance, we will generate source parameters randomly, generate the associated signal and inject it on Gaussian noise colored according to example LIGO-Virgo PSDs.\n",
    "\n",
    "This is done in the cell below (it's not super important to follow every step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c480665b-6bca-4723-8508-2e06491d4990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_injection_dic(seed):\n",
    "    aux_prior = cogwheel.gw_prior.IASPrior(\n",
    "        f_ref=100.0,\n",
    "        mchirp_range=(10, 50),\n",
    "        detector_pair='HL',\n",
    "        tgps=0,\n",
    "        ref_det_name='H',\n",
    "        f_avg=100.0,\n",
    "        d_hat_max=100.0,\n",
    "        dt0=10,\n",
    "    )\n",
    "    injection_dic = dict(\n",
    "        aux_prior.generate_random_samples(1, seed=seed).loc[0, aux_prior.standard_params])\n",
    "    return injection_dic\n",
    "\n",
    "\n",
    "def get_event_data(seed=0):\n",
    "    \"\"\"Return an EventData with a secret injection in it.\"\"\"\n",
    "    injection_dic = _generate_injection_dic(seed)\n",
    "\n",
    "    asd_funcs = list(cogwheel.data.ASDS)\n",
    "\n",
    "    eventname = f'GW{seed}'\n",
    "    event_data = cogwheel.data.EventData.gaussian_noise(\n",
    "        eventname, duration=128.0, detector_names='HLV', fmax=512.0,\n",
    "        asd_funcs=asd_funcs, tgps=0.0, seed=seed)\n",
    "\n",
    "    event_data.inject_signal(par_dic=injection_dic, approximant='IMRPhenomXODE')\n",
    "\n",
    "    return event_data\n",
    "\n",
    "\n",
    "event_data = get_event_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce2a82a-9ed8-44d9-9b0e-34678dc2d719",
   "metadata": {},
   "source": [
    "Let's plot a spectrogram of the whitened data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded35c96-0321-45a2-ab77-38eab9c07971",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = (-30, 30)  # Edit this\n",
    "event_data.specgram(xlim=xlim);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f23aa-eda7-4c46-b802-c5cf6c7c2550",
   "metadata": {},
   "source": [
    "A spectrogram is a time-frequency representation of the data.\n",
    "The horizontal axis is time, the vertical axis frequency, and the color power.\n",
    "You can think of the columns of a spectrogram as short-time PSDs.\n",
    "The panels of the plot show different detectors.\n",
    "\n",
    "* Find the event, estimate the merger time (hint: adjust `xlim` to best display the event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8a15a-99c9-4d83-9f7f-718630702ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_merger_guess = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea959c2a-f4fc-441f-a73b-4c6ef41d1661",
   "metadata": {},
   "source": [
    "`cogwheel` uses an algorithm called relative-binning to speed up likelihood computations.\n",
    "This method requires a reference waveform that is a good fit to the signal.\n",
    "We will obtain this well-fitting waveform by maximizing the likelihood, but this requires an initial guess for the mass.\n",
    "\n",
    "Can we guess the mass of the signal by inspecting the data?\n",
    "Recall that the time to merger depends on the chirp-mass and the frequency as\n",
    "$$\n",
    "    f^{-8/3} = \\frac{(8\\pi)^{8/3}}{5} \\left(\\frac{G \\mathcal{M}}{c^3}\\right)^{5/3} (t_\\mathrm{merger} - t)\n",
    "$$\n",
    "\n",
    "* Which stays longer in the detector frequency band: a heavy or a light signal?\n",
    "* From the spectrogram, estimate the time to merger as a function of frequency and from there guess the (detector frame, i.e. redshifted) chirp mass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98851b63-5034-474d-b7dd-77745ce5c19f",
   "metadata": {},
   "source": [
    "Another plot we can do is that of the whitened data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdefe68a-4c5a-4b05-95ae-b20660676528",
   "metadata": {},
   "outputs": [],
   "source": [
    "whitened_td = event_data.get_whitened_td()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5674dc6-335e-4faa-b865-ee93837d96c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(event_data.detector_names), sharex=True, sharey=True)\n",
    "for det_name, ax, wht_strain in zip(event_data.detector_names, axs, whitened_td):\n",
    "    ax.plot(event_data.times - event_data.tcoarse, wht_strain)\n",
    "    ax.grid()\n",
    "    ax.set_title(det_name, loc='left')\n",
    "\n",
    "ax.set_xlim(xlim)\n",
    "fig.supxlabel('Time (s)')\n",
    "fig.supylabel('Whitened data')\n",
    "fig.suptitle(event_data.eventname);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb38b52-c7f4-4097-a587-7f575b6bee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same but just one detector\n",
    "i_det = 0\n",
    "det_name = event_data.detector_names[i_det]\n",
    "wht_strain = whitened_td[i_det]\n",
    "plt.figure()\n",
    "plt.plot(event_data.times - event_data.tcoarse, wht_strain)\n",
    "plt.grid()\n",
    "plt.title(det_name, loc='left')\n",
    "\n",
    "plt.xlim(xlim)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Whitened data')\n",
    "plt.title(event_data.eventname);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e863b1-1cae-4241-b4d8-a27260eea499",
   "metadata": {},
   "source": [
    "We can get another crude estimate of the chirp mass as follows (inspired by https://arxiv.org/pdf/1608.01940 Sec 2)\n",
    "* Estimate the frequency of the wave as a function of time\n",
    "* Estimate the slope of $f^{-8/3}(t)$.\n",
    "* Estimate the chirp mass\n",
    "> *Note:* in the code we may work assuming units of solar masses or Hertz, so actually\n",
    "> \\begin{align}\n",
    "      \\texttt{mchirp} &= \\frac{\\mathcal{M}}{M_\\odot} \\\\\n",
    "      \\texttt{freq} &= \\frac{f}{\\rm Hz}\n",
    "  \\end{align}\n",
    "> A handy conversion factor is\n",
    "> $$\n",
    "     \\frac{G M_\\odot}{c^3 \\, \\text{Hz}} = 4.9 \\cdot 10^{-6},\n",
    "  $$\n",
    "> provided in LAL (LIGO-Virgo-KAGRA Algorithm Library) as `lal.MTSUN_SI`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae454d09-600b-4c8d-bac8-6f559e51e517",
   "metadata": {},
   "outputs": [],
   "source": [
    "lal.MTSUN_SI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b9c184-8c8f-491e-b2c7-43ebc4b9351d",
   "metadata": {},
   "source": [
    "### Example solution (but try yourself, many solution strategies possible!)\n",
    "\n",
    "Find zero-crossings of the whitened data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c137014-1f3f-4e80-9836-b8c5c78d1d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_det = 0\n",
    "xlim = 1.45, 1.63\n",
    "\n",
    "det_name = event_data.detector_names[i_det]\n",
    "wht_strain = whitened_td[i_det]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(event_data.times - event_data.tcoarse, wht_strain)\n",
    "plt.grid()\n",
    "plt.title(det_name, loc='left')\n",
    "\n",
    "plt.xlim(xlim)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Whitened data')\n",
    "plt.title(event_data.eventname)\n",
    "\n",
    "ascending_zero_crossings = 1.513, 1.53, 1.545, 1.555, 1.565, 1.573, 1.581, 1.588, 1.594\n",
    "plt.scatter(ascending_zero_crossings, [0] * len(ascending_zero_crossings), c='r', marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b39659-9cdf-4820-9454-c5221cbfc611",
   "metadata": {},
   "source": [
    "Find frequencies from these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f1d75-ba5b-43d3-91bb-11ae918da87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = np.diff(ascending_zero_crossings)\n",
    "times = np.add(ascending_zero_crossings[:-1], ascending_zero_crossings[1:]) / 2\n",
    "frequencies = 1 / periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4495049a-be91-40a2-bc6d-9a9c09276ce5",
   "metadata": {},
   "source": [
    "Linear fit $f^{-8/3}$ vs $t$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef60815e-0242-4c71-9392-8df0f54ed1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = frequencies**(-8/3)\n",
    "x = times\n",
    "\n",
    "# Perform linear fit\n",
    "slope, const = np.polyfit(times, y, deg=1)\n",
    "\n",
    "# Generate fitted line for plotting\n",
    "x_fit = np.linspace(x.min(), x.max(), 500)\n",
    "y_fit = slope * x_fit + const\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.scatter(x, y, label='Data')\n",
    "plt.plot(x_fit, y_fit, 'r--', label=rf'Fit: $y = {slope:.3g} x + {const:.3g}$')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency$^{-8/3}$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db7fab-b776-43a7-b116-e3c3b258b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slope == (8*np.pi)**(8/3) / 5 * (lal.MTSUN_SI * mchirp)**(5/3)\n",
    "mchirp_guess = (-slope / (8*np.pi)**(8/3) * 5)**(3/5) / lal.MTSUN_SI\n",
    "print(mchirp_guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb50b1b-6fb3-4e86-943d-833a3e5e43fd",
   "metadata": {},
   "source": [
    "## Find a well-fitting waveform\n",
    "Armed with our guess (which normally one would get from the search pipeline...), we can now do a fast likelihood maximization to find our reference waveform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce4eee-8ff7-43d7-ab18-611cc3da2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "approximant = 'IMRPhenomXAS'\n",
    "prior_class = 'IntrinsicAlignedSpinIASPrior'\n",
    "\n",
    "posterior = cogwheel.posterior.Posterior.from_event(\n",
    "    event_data,\n",
    "    mchirp_guess,\n",
    "    approximant,\n",
    "    prior_class,\n",
    "    ref_wf_finder_kwargs={\n",
    "        'f_ref': 100.0,  # Just so it matches the injection and it makes sense to compare parameters\n",
    "        'time_range': (t_merger_guess - 0.1, t_merger_guess + 0.1)  # Edit if needed\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec10cef-e248-4829-89e1-ab7a06b0d880",
   "metadata": {},
   "source": [
    "Now we have a (crude) best-fit waveform, which is stored in `posterior.likelihood.par_dic_0`.\n",
    "Only the most important parameters have been optimized and some approximations have been made, but if everything went well we should hve a decent fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fde2b2-98b9-4fdd-87b9-53de2fb773e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.likelihood.par_dic_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767e9d2b-f016-4149-84f2-6dbb46819ca3",
   "metadata": {},
   "source": [
    "* How does this fit compare to your initial guess? Recall $\\mathcal{M} = (m_1 m_2)^{5/6} / (m_1 + m_2)^{1/6}$\n",
    "\n",
    "We can inspect whether we have a decent fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3820ebdb-9af0-4f13-a147-13e3370ebfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.likelihood.plot_whitened_wf(posterior.likelihood.par_dic_0, trng=xlim);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c5f94-1ed4-40db-bbaf-6e780933eeb2",
   "metadata": {},
   "source": [
    "## Sample the posterior\n",
    "\n",
    "### `cogwheel` basics\n",
    "The `posterior` object contains a `posterior.prior` and a `posterior.likelihood`. The posterior and the prior are distributions over the space of parameters.\n",
    "We will use two sytems of coordinates: **sampled parameters** $\\vartheta$ and **standard parameters** $\\theta$.\n",
    "* **Sampled parameters** are intended to remove correlations from the posterior. We express the posterior in these coordinates to ease sampling.\n",
    "* **Standard parameters** are of astrophysical interest, and are understood by waveform modeling libraries (and fellow astrophysicists). The likelihood class uses standard parameters, so that we don't need to redefine it if we want to switch sampling coordinates.\n",
    "\n",
    "The transformations between them are provided by the `posterior.prior` object:\n",
    "* $\\texttt{prior.sampled\\_params} = \\vartheta$ names\n",
    "* $\\texttt{prior.standard\\_params} = \\theta$ names\n",
    "* $\\texttt{prior.transform} : \\vartheta \\to \\theta$\n",
    "* $\\texttt{prior.inverse\\_transform} : \\theta \\to \\vartheta$\n",
    "\n",
    "The methods `posterior.lnposterior`, `posterior.prior.lnprior` and `posterior.likelihood.lnlike` are related by:\n",
    "$$\n",
    "    \\mathcal{P}(\\vartheta \\mid d) = \\pi(\\vartheta) \\mathcal{L}(d \\mid \\theta).\n",
    "$$\n",
    "\n",
    "### Extrinsic-parameter marginalization\n",
    "\n",
    "Extrinsic parameters have a known functional form in the prior and likelihood, which allows to marginalize them semianalytically.\n",
    "This reduces the dimensionality of the parameter space and speeds up sampling. To use this feature, we simply choose a prior for the intrinsic parameters (`'IntrinsicAlignedSpinIASPrior'`), and `cogwheel` understands that we want to use a marginalized likelihood $\\overline{\\mathcal{L}}(\\theta_\\mathrm{int} \\mid d)$.\n",
    "\n",
    "* Think of all the parameters that characterize a GW source. What do you expect the standard parameters to be in this case?\n",
    "* Check in the `posterior.prior` object: what are the sampled parameters and standard parameters? Does this make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba2742d-65b8-4203-a1eb-c9d7536ff24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = cogwheel.sampling.Nautilus(posterior)\n",
    "# These trade off quality and speed:\n",
    "sampler.run_kwargs['n_live'] = 1000\n",
    "sampler.run_kwargs['n_eff'] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b32d96-9421-43b5-aeb5-04c86957c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rundir = sampler.get_rundir(parentdir='pe_runs')\n",
    "sampler.run(rundir)  # Will take a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2f3d2c-8e47-4abd-9f2b-46537b86f5c9",
   "metadata": {},
   "source": [
    "Let's load the samples. They are in the form of a dataframe (table) where the columns are parameters of the source, and the rows are samples from the posterior.\n",
    "\n",
    "> **Note:** Some samplers like [nautilus](https://nautilus-sampler.readthedocs.io/en/latest/) produce *weighted* posterior samples. Notice that the dataframe contains a column `\"weights\"`. For example, to make a histogram you would do\n",
    "> ```python\n",
    "> plt.hist(samples['m1'], weights=samples['weights'])\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29998e8-f488-440c-ae26-31081874f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_feather(rundir/'samples.feather')\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ec9913-d612-4f4e-9395-391c26d31402",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40b44c1-5cab-4d01-8d35-b588bfb34149",
   "metadata": {},
   "source": [
    "DataFrames allow to easily add columns. Let's add some derived quantities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a2dca-9a7f-42cb-a566-40bc23082160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_derived_quantities(samples):\n",
    "    \"\"\"\n",
    "    Add columns inplace to a dataframe of samples.\n",
    "\n",
    "    Includes redshift, mtot, m1_source, m2_source, mtot_source, chieff, q.\n",
    "    \"\"\"\n",
    "    samples['redshift'] = cogwheel.cosmology.z_of_d_luminosity(samples['d_luminosity'])\n",
    "\n",
    "    samples['mtot'] = samples['m1'] + samples['m2']\n",
    "\n",
    "    for mass_key in 'm1', 'm2', 'mtot':\n",
    "        samples[f'{mass_key}_source'] = samples[mass_key] / (1 + samples['redshift'])\n",
    "\n",
    "    samples['chieff'] = cogwheel.gw_utils.chieff(**samples[['m1', 'm2', 's1z', 's2z']])\n",
    "\n",
    "    samples['q'] = samples['m2'] / samples['m1']\n",
    "\n",
    "\n",
    "add_derived_quantities(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15bf0b-7d9a-4e80-858a-7bc7e820b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = [\n",
    "    # 'mchirp',\n",
    "    # 'lnq',\n",
    "    # 'chieff',\n",
    "    # 'cumchidiff',\n",
    "    # 'weights',\n",
    "    'm1',\n",
    "    'm2',\n",
    "    's1z',\n",
    "    's2z',\n",
    "    # 'l1',\n",
    "    # 'l2',\n",
    "    # 'f_ref',\n",
    "    'd_luminosity',\n",
    "    'ra',\n",
    "    'dec',\n",
    "    # 'lon',\n",
    "    'phi_ref',\n",
    "    'psi',\n",
    "    'iota',\n",
    "    't_geocenter',\n",
    "    # 'lnl_marginalized',\n",
    "    'lnl',\n",
    "    # 'h_h',\n",
    "    # 'n_effective',\n",
    "    # 'n_qmc',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0046ab82-fb23-4044-8a79-860078200a08",
   "metadata": {},
   "source": [
    "If you haven't before, it is good to spend some time staring at a corner plot of the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5b91e-c089-4698-b6ab-217a25c43146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: cogwheel.gw_plotting.CornerPlot understands the weights automatically\n",
    "corner_plot = cogwheel.gw_plotting.CornerPlot(\n",
    "    samples, params=plot_params, tail_probability=1e-4\n",
    ")\n",
    "corner_plot.plot(title=event_data.eventname)\n",
    "\n",
    "# Let's also reveal the true (injected) value\n",
    "corner_plot.scatter_points(event_data.injection['par_dic'], colors=['C3'], s=150,\n",
    "                           zorder=2, marker='+', adjust_lims=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e91a979-c295-4c66-b5ce-627fdb3de510",
   "metadata": {},
   "source": [
    "A corner plot shows 1d histograms in the diagonal, and 2d histograms of every parameter against every other off-diagonal.\n",
    "\n",
    "* What parameters are correlated? Can you think of reasons why these correlations arise?\n",
    "* Look at the log likelihood-ratio of the samples. Can you estimate the SNR of the signal?\n",
    "* Are any parameters discrepant with the injection? Is this expected?\n",
    "\n",
    "One subtlety is that the injection was made with the waveform model (approximant) `IMRPhenomXODE`, and the parameter inference with `IMRPhenomXAS` (which parameters should have the same physical meaning in both cases? which not?).\n",
    "\n",
    "\n",
    "## Extra\n",
    "\n",
    "\n",
    "`IMRPhenomXAS` only describes the quadrupolar radiation and assumes the spins are aligned.\n",
    "This helped simplify some computations and reduced the dimensionality of the parameter space, but we can get more accurate results.\n",
    "\n",
    "Let's now use `IMRPhenomXODE`, a more refined model that includes precession and higher-order harmonics, to do the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe4582a-a2b1-4577-a060-eef92a070906",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_xode = cogwheel.posterior.Posterior.from_event(\n",
    "    event_data,\n",
    "    mchirp_guess,\n",
    "    approximant='IMRPhenomXODE',\n",
    "    prior_class='IntrinsicIASPrior',\n",
    "    ref_wf_finder_kwargs={\n",
    "        'f_ref': 100.0,  # Just so it matches the injection and it makes sense to compare parameters\n",
    "        'time_range': (t_merger_guess - 0.1, t_merger_guess + 0.1)  # Edit if needed\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71377a-721f-48be-971e-a1b0cf0bff8c",
   "metadata": {},
   "source": [
    "* Note that we use a different prior class because now we have generic spins. Which are the sampled and standard parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eb9e73-570f-4b98-a8a6-65520a803931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the fit makes sense\n",
    "posterior_xode.likelihood.plot_whitened_wf(posterior_xode.likelihood.par_dic_0)\n",
    "plt.xlim(xlim);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a07a87-4beb-462d-8ba2-9fa460765620",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_xode = cogwheel.sampling.Nautilus(posterior_xode)\n",
    "sampler_xode.run_kwargs['n_live'] = 1000\n",
    "sampler_xode.run_kwargs['n_eff'] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c43dc-4928-426a-b26e-de37996e522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rundir_xode = sampler_xode.get_rundir(parentdir='pe_runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5578c9-0fa7-4348-b94c-9147179fa6c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sampler_xode.run(rundir_xode)  # Will take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85266f9-afb9-4573-a312-2ff7d36ef82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_xode = pd.read_feather(rundir_xode/'samples.feather')\n",
    "add_derived_quantities(samples_xode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1628a3d-0c5c-4df7-b1d2-0f1db7bbce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_plot = cogwheel.gw_plotting.CornerPlot(samples_xode, params=plot_params, tail_probability=1e-4)\n",
    "corner_plot.plot(title=event_data.eventname)\n",
    "\n",
    "corner_plot.scatter_points(event_data.injection['par_dic'], colors=['C3'], s=150,\n",
    "                           zorder=2, marker='+', adjust_lims=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efae9eb-8e0a-4cd8-8530-4227c45f5887",
   "metadata": {},
   "source": [
    "Let's compare the two runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f245a-0ed7-4cb4-b46c-914a0ef351c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_corner_plot = cogwheel.gw_plotting.MultiCornerPlot(\n",
    "    {'IMRPhenomXAS': samples,\n",
    "     'IMRPhenomXODE': samples_xode}\n",
    "    , params=plot_params, tail_probability=1e-4)\n",
    "multi_corner_plot.plot(title=event_data.eventname)\n",
    "\n",
    "multi_corner_plot.scatter_points(event_data.injection['par_dic'], colors=['k'], s=150,\n",
    "                                 zorder=2, marker='+', adjust_lims=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff47e6-bcd0-4fc6-85e6-8db1072bdeaf",
   "metadata": {},
   "source": [
    "The difference between these two runs is that IMRPhenomXODE includes the effects of misaligned spins (precession) and harmonic modes $(\\ell, |m|)$ other than the quadrupole $(2, 2)$.\n",
    "* Which parameters are affected the most, and the least? Does this make sense to you?\n",
    "* Which model best fits the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b425ebdc-786f-41f7-8b7d-65bef179ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_xode.load_evidence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c393fd-2e64-492f-8b05-d18e0d3f4dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.load_evidence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd4b26-cde7-4939-a774-ed22d237db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit = samples_xode.iloc[samples_xode['lnl'].idxmax()]\n",
    "fig = sampler_xode.posterior.likelihood.plot_whitened_wf(best_fit, trng=(-.4, .2))\n",
    "fig.suptitle(event_data.eventname)\n",
    "plt.xlim(xlim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63115fea-38ce-452a-8462-6844cafe75b7",
   "metadata": {},
   "source": [
    "## Extra 2\n",
    "\n",
    "Now you can infer the parameters of a real event!\n",
    "\n",
    "This is how you would obtain the `EventData` object in `cogwheel`:\n",
    "\n",
    "```python\n",
    "eventname = 'GW190412'\n",
    "filenames, detector_names, tgps = cogwheel.data.download_timeseries(eventname)\n",
    "event_data = cogwheel.data.EventData.from_timeseries(\n",
    "    filenames, eventname, detector_names, tgps)\n",
    "```\n",
    "\n",
    "GW190412 [https://arxiv.org/pdf/2004.08342] is a real-world example of the effects of adding higher modes on parameter inference. Can you reproduce the conclusion of Fig. 4 of that paper?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
